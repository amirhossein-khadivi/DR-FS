{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ mat\n",
        "data = loadmat('/content/bcdr_data_whole.mat')\n",
        "\n",
        "# Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØªÙˆØ§ÛŒ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "m3Wqh0tXaN2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa5011a-705d-4e97-d1c7-9c9b237159a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Mon May 25 23:33:54 2020', '__version__': '1.0', '__globals__': [], 'X': array([[2.17372803e+02, 2.26000000e+02, 3.34304314e+01, ...,\n",
            "        4.09711838e+01, 5.43651000e-04, 7.60290289e+00],\n",
            "       [1.34569305e+02, 1.32000000e+02, 1.64031601e+01, ...,\n",
            "        5.33333321e+01, 2.89329200e-03, 6.81921005e+00],\n",
            "       [1.29835617e+02, 1.31000000e+02, 1.75003757e+01, ...,\n",
            "        1.62746525e+01, 1.58815900e-03, 7.04570007e+00],\n",
            "       ...,\n",
            "       [6.03789749e+01, 6.10000000e+01, 6.78357172e+00, ...,\n",
            "        5.33712101e+00, 1.20207380e-02, 5.62138128e+00],\n",
            "       [1.17874023e+02, 1.08000000e+02, 4.94650116e+01, ...,\n",
            "        1.67071896e+01, 3.75119000e-04, 7.84101486e+00],\n",
            "       [1.94227890e+02, 1.94000000e+02, 3.78509216e+01, ...,\n",
            "        4.87280769e+01, 3.98454000e-04, 8.16876030e+00]]), 'Y': array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1]], dtype=uint8)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data['X'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnToLJCy-65a",
        "outputId": "552e28b9-e34f-400d-d3bb-a82952fc2c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=data['Y']\n",
        "x=data['X']"
      ],
      "metadata": {
        "id": "puUHbZsMb_wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# ğŸ“¥ 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øª\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# ğŸ¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§\n",
        "X = data.data\n",
        "y = data.target  # 0: Ø¨Ø¯Ø®ÛŒÙ… (malignant), 1: Ø®ÙˆØ´â€ŒØ®ÛŒÙ… (benign)\n",
        "\n",
        "# ğŸ” Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ\n",
        "#print(\"ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:\", data.feature_names)\n",
        "#print(\"ØªÙˆØ¶ÛŒØ­Ø§Øª:\", data.DESCR[:500], '...')  # ÙÙ‚Ø· ÛµÛ°Û° Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ÙˆÙ„\n",
        "#print(\"Ø´Ú©Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:\", X.shape)\n",
        "#print(\"Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§:\", set(y))\n",
        "\n",
        "# ğŸ§ª 2. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ğŸ”„ 3. Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§\n",
        "#scaler = StandardScaler()\n",
        "#X_train = scaler.fit_transform(X_train)\n",
        "#X_test = scaler.transform(X_test)\n",
        "\n",
        "# âœ… Ø¢Ù…Ø§Ø¯Ù‡â€ŒÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ML ÛŒØ§ deep learning\n"
      ],
      "metadata": {
        "id": "OqTa61OgPl4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75LXVY2G33D6",
        "outputId": "0180d61e-fe04-4e8f-face-464dcb3750cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bottleneck dim from PCA: 10\n",
            "Run 1: Acc=0.9561, F1=0.9645, AUC=0.9951, Prec=0.9714, Recall=0.9577\n",
            "Run 2: Acc=0.9561, F1=0.9645, AUC=0.9866, Prec=0.9714, Recall=0.9577\n",
            "Run 3: Acc=0.9561, F1=0.9645, AUC=0.9925, Prec=0.9714, Recall=0.9577\n",
            "Run 4: Acc=0.9561, F1=0.9645, AUC=0.9921, Prec=0.9714, Recall=0.9577\n",
            "Run 5: Acc=0.9561, F1=0.9645, AUC=0.9836, Prec=0.9714, Recall=0.9577\n",
            "Run 6: Acc=0.9561, F1=0.9645, AUC=0.9961, Prec=0.9714, Recall=0.9577\n",
            "Run 7: Acc=0.9561, F1=0.9645, AUC=0.9918, Prec=0.9714, Recall=0.9577\n",
            "Run 8: Acc=0.9561, F1=0.9645, AUC=0.9872, Prec=0.9714, Recall=0.9577\n",
            "Run 9: Acc=0.9561, F1=0.9645, AUC=0.9951, Prec=0.9714, Recall=0.9577\n",
            "Run 10: Acc=0.9561, F1=0.9645, AUC=0.9912, Prec=0.9714, Recall=0.9577\n",
            "\n",
            "=== Summary over runs ===\n",
            "Mean Accuracy:  0.9561 Â± 0.0000\n",
            "Mean F1:       0.9645 Â± 0.0000\n",
            "Mean AUC:      0.9911 Â± 0.0039\n",
            "Mean Precision:0.9714 Â± 0.0000\n",
            "Mean Recall:   0.9577 Â± 0.0000\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import loadmat\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, roc_auc_score, recall_score, precision_score\n",
        "import numpy as np\n",
        "\n",
        "# ğŸ’¾ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ .mat\n",
        "#data = loadmat('/content/bcdr_data_whole.mat')\n",
        "#X = data['X']\n",
        "#y = data['Y']\n",
        "\n",
        "# ğŸ”§ Ø§ØµÙ„Ø§Ø­ Ø´Ú©Ù„ y\n",
        "#y = y.squeeze()  # Ø­Ø§Ù„Ø§ y Ø´Ú©Ù„Ø´ (n,) ÛŒØ§ (n,1) Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯\n",
        "\n",
        "# ğŸ§ª ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ğŸ”„ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ\n",
        "scaler = StandardScaler()\n",
        "X_trainval = scaler.fit_transform(X_trainval)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# ğŸ”» Ú©Ø§Ù‡Ø´ Ø¨Ø¹Ø¯ Ø¨Ø§ PCA\n",
        "pca = PCA(n_components=0.95)\n",
        "pca.fit(X_trainval)\n",
        "bottleneck_dim = pca.n_components_\n",
        "print(f\"Bottleneck dim from PCA: {bottleneck_dim}\")\n",
        "\n",
        "# ğŸ§  ØªØ¹Ø±ÛŒÙ Ø§Ù†Ú©ÙˆØ¯Ø± Ùˆ Ú©Ù„Ø§Ø³ÛŒÙØ§ÛŒØ±\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, bottleneck_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, bottleneck_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, bottleneck_dim):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.classifier = nn.Linear(bottleneck_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.classifier(x))\n",
        "\n",
        "# ğŸš€ ØªØ§Ø¨Ø¹ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
        "def train_and_evaluate(X_trainval, y_trainval, X_test, y_test, bottleneck_dim, device):\n",
        "    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ØªÙ†Ø³ÙˆØ±\n",
        "    X_trainval_tensor = torch.tensor(X_trainval, dtype=torch.float32).to(device)\n",
        "    y_trainval_tensor = torch.tensor(y_trainval.squeeze(), dtype=torch.float32).unsqueeze(1).to(device)\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    y_test_tensor = torch.tensor(y_test.squeeze(), dtype=torch.int32)\n",
        "\n",
        "    encoder = Encoder(input_dim=X_trainval.shape[1], bottleneck_dim=bottleneck_dim).to(device)\n",
        "    classifier = Classifier(bottleneck_dim=bottleneck_dim).to(device)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=1e-3)\n",
        "\n",
        "    epochs = 20\n",
        "    for epoch in range(epochs):\n",
        "        encoder.train()\n",
        "        classifier.train()\n",
        "        optimizer.zero_grad()\n",
        "        z = encoder(X_trainval_tensor)\n",
        "        y_pred = classifier(z)\n",
        "        loss = criterion(y_pred, y_trainval_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÙˆÛŒ ØªØ³Øª\n",
        "    encoder.eval()\n",
        "    classifier.eval()\n",
        "    with torch.no_grad():\n",
        "        z_test = encoder(X_test_tensor)\n",
        "        y_test_pred_prob = classifier(z_test).cpu().numpy().flatten()\n",
        "        y_test_pred_labels = (y_test_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§\n",
        "    accuracy = (y_test_pred_labels == y_test_tensor.numpy()).mean()\n",
        "    f1 = f1_score(y_test_tensor, y_test_pred_labels, zero_division=0)\n",
        "    precision = precision_score(y_test_tensor, y_test_pred_labels, zero_division=0)\n",
        "    recall = recall_score(y_test_tensor, y_test_pred_labels, zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_test_tensor, y_test_pred_prob)\n",
        "    except ValueError:\n",
        "        auc = 0.5\n",
        "\n",
        "    return accuracy, f1, auc, precision, recall, y_test_pred_prob\n",
        "\n",
        "# âš¡ Ø§Ø¬Ø±Ø§ÛŒ Ú†Ù†Ø¯Ø¨Ø§Ø±Ù‡\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_runs = 10\n",
        "accuracies, f1_scores, aucs, precisions, recalls = [], [], [], [], []\n",
        "\n",
        "for run in range(num_runs):\n",
        "    acc, f1, auc, prec, rec, y_test_pred_prob = train_and_evaluate(X_trainval, y_trainval, X_test, y_test, bottleneck_dim, device)\n",
        "    print(f\"Run {run+1}: Acc={acc:.4f}, F1={f1:.4f}, AUC={auc:.4f}, Prec={prec:.4f}, Recall={rec:.4f}\")\n",
        "    accuracies.append(acc)\n",
        "    f1_scores.append(f1)\n",
        "    aucs.append(auc)\n",
        "    precisions.append(prec)\n",
        "    recalls.append(rec)\n",
        "\n",
        "print(\"\\n=== Summary over runs ===\")\n",
        "print(f\"Mean Accuracy:  {np.mean(accuracies):.4f} Â± {np.std(accuracies):.4f}\")\n",
        "print(f\"Mean F1:       {np.mean(f1_scores):.4f} Â± {np.std(f1_scores):.4f}\")\n",
        "print(f\"Mean AUC:      {np.mean(aucs):.4f} Â± {np.std(aucs):.4f}\")\n",
        "print(f\"Mean Precision:{np.mean(precisions):.4f} Â± {np.std(precisions):.4f}\")\n",
        "print(f\"Mean Recall:   {np.mean(recalls):.4f} Â± {np.std(recalls):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_labels = (y_test_pred_prob >= 0.8).astype(int)\n",
        "accuracy = (y_test_pred_labels == y_test).mean()\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRZc9LFH5c52",
        "outputId": "881e7550-535e-4249-cf16-e431fdf34fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.8333333333333334)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "7!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_1dRVMu78Ov",
        "outputId": "5f7d6237-454c-480c-f543-42e891520fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "import optuna\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Ø¨Ø±Ø§ÛŒ reproducibility\n",
        "#torch.manual_seed(42)\n",
        "#np.random.seed(42)\n",
        "\n",
        "# âœ… 1) Ø¯Ø§Ø¯Ù‡ Ø³Ø§Ø®ØªÚ¯ÛŒ\n",
        "X, y = make_classification(n_samples=50, n_features=500, n_classes=2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train+val Ùˆ test\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# âœ… 2) ØªØ®Ù…ÛŒÙ† Ø§ÙˆÙ„ÛŒÙ‡ bottleneck_dim Ø¨Ø§ PCA\n",
        "pca = PCA(n_components=0.95)  # 95% ÙˆØ§Ø±ÛŒØ§Ù†Ø³\n",
        "pca.fit(X_trainval)\n",
        "initial_bottleneck = pca.n_components_\n",
        "print(f\"Initial bottleneck_dim from PCA: {initial_bottleneck}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# âœ… 3) ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, bottleneck_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, bottleneck_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, bottleneck_dim):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.clf = nn.Linear(bottleneck_dim, 1)\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.clf(x))\n",
        "\n",
        "\n",
        "# âœ… 4) ØªØ§Ø¨Ø¹ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
        "def train_and_evaluate(X_trainval, y_trainval, X_test, y_test, bottleneck_dim, hidden_dim, lr, device):\n",
        "    X_trainval_tensor = torch.tensor(X_trainval, dtype=torch.float32).to(device)\n",
        "    y_trainval_tensor = torch.tensor(y_trainval, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "    encoder = Encoder(input_dim=X_trainval.shape[1], hidden_dim=hidden_dim, bottleneck_dim=bottleneck_dim).to(device)\n",
        "    classifier = Classifier(bottleneck_dim=bottleneck_dim).to(device)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=lr)\n",
        "\n",
        "    epochs = 30\n",
        "    encoder.train()\n",
        "    classifier.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        z = encoder(X_trainval_tensor)\n",
        "        y_pred = classifier(z)\n",
        "        loss = criterion(y_pred, y_trainval_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÙˆÛŒ ØªØ³Øª\n",
        "    encoder.eval()\n",
        "    classifier.eval()\n",
        "    with torch.no_grad():\n",
        "        z_test = encoder(X_test_tensor)\n",
        "        y_test_pred = classifier(z_test).cpu().numpy()\n",
        "        y_test_labels = (y_test_pred >= 0.5).astype(int)\n",
        "\n",
        "        acc = accuracy_score(y_test, y_test_labels)\n",
        "        f1 = f1_score(y_test, y_test_labels)\n",
        "        auc = roc_auc_score(y_test, y_test_pred)\n",
        "        prec = precision_score(y_test, y_test_labels)\n",
        "        rec = recall_score(y_test, y_test_labels)\n",
        "    return acc, f1, auc, prec, rec\n",
        "\n",
        "\n",
        "# âœ… 5) ØªØ§Ø¨Ø¹ Ù‡Ø¯Ù Ø¨Ø±Ø§ÛŒ Optuna\n",
        "def objective(trial):\n",
        "    bottleneck_dim = trial.suggest_int('bottleneck_dim', 10, initial_bottleneck)\n",
        "    hidden_dim = trial.suggest_int('hidden_dim', 32, 256)\n",
        "    lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
        "\n",
        "    val_f1_scores = []\n",
        "    for run in range(3):  # Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ú†Ù†Ø¯ Ø¨Ø§Ø± ØªÚ©Ø±Ø§Ø±\n",
        "        acc, f1, auc, prec, rec = train_and_evaluate(\n",
        "            X_trainval, y_trainval, X_test, y_test, bottleneck_dim, hidden_dim, lr, device\n",
        "        )\n",
        "        val_f1_scores.append(f1)\n",
        "\n",
        "    mean_f1 = np.mean(val_f1_scores)\n",
        "    return mean_f1  # Ù‡Ø¯Ù: Ø¨ÛŒØ´ÛŒÙ†Ù‡ Ú©Ø±Ø¯Ù† F1\n",
        "\n",
        "\n",
        "# âœ… 6) Ø§Ø¬Ø±Ø§ÛŒ optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(f\"\\nâœ… Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:\")\n",
        "print(study.best_params)\n",
        "\n",
        "# âœ… 7) Ø¢Ù…ÙˆØ²Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ± Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÙˆÛŒ test\n",
        "best_params = study.best_params\n",
        "final_acc, final_f1, final_auc, final_prec, final_rec = train_and_evaluate(\n",
        "    X_trainval, y_trainval, X_test, y_test,\n",
        "    bottleneck_dim=best_params['bottleneck_dim'],\n",
        "    hidden_dim=best_params['hidden_dim'],\n",
        "    lr=best_params['lr'],\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“Š Final Test Results:\")\n",
        "print(f\"Accuracy: {final_acc:.4f}\")\n",
        "print(f\"F1-score: {final_f1:.4f}\")\n",
        "print(f\"AUC: {final_auc:.4f}\")\n",
        "print(f\"Precision: {final_prec:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {final_rec:.4f}\")\n",
        "print(f\"Specificity: {1 - final_rec:.4f}\")  # Ø¨Ø±Ø§ÛŒ ØªØ³Øª: 1 - recall Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù†ÙÛŒ\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9Lfqlhp4Agn",
        "outputId": "6e32e214-7655-4099-803b-1c7b6f2acbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-03 15:40:28,462] A new study created in memory with name: no-name-7fa0e324-b782-4cb4-9477-fec0bf6cc3b2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial bottleneck_dim from PCA: 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-03 15:40:28,923] Trial 0 finished with value: 0.6222222222222222 and parameters: {'bottleneck_dim': 35, 'hidden_dim': 78, 'lr': 0.0004947407944969044}. Best is trial 0 with value: 0.6222222222222222.\n",
            "[I 2025-07-03 15:40:29,205] Trial 1 finished with value: 0.7167277167277167 and parameters: {'bottleneck_dim': 12, 'hidden_dim': 35, 'lr': 0.003833725566317183}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:29,670] Trial 2 finished with value: 0.6444444444444444 and parameters: {'bottleneck_dim': 23, 'hidden_dim': 161, 'lr': 0.0003883861967460078}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:30,042] Trial 3 finished with value: 0.6262626262626262 and parameters: {'bottleneck_dim': 11, 'hidden_dim': 52, 'lr': 0.00973128001236248}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:30,417] Trial 4 finished with value: 0.6655011655011654 and parameters: {'bottleneck_dim': 29, 'hidden_dim': 78, 'lr': 0.00020497456941332386}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:30,764] Trial 5 finished with value: 0.5818181818181818 and parameters: {'bottleneck_dim': 14, 'hidden_dim': 78, 'lr': 0.0027297282237809793}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:31,068] Trial 6 finished with value: 0.38888888888888884 and parameters: {'bottleneck_dim': 19, 'hidden_dim': 70, 'lr': 0.00010496914167117156}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:31,324] Trial 7 finished with value: 0.48412698412698413 and parameters: {'bottleneck_dim': 35, 'hidden_dim': 34, 'lr': 0.00010978628759541696}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:31,605] Trial 8 finished with value: 0.6142191142191142 and parameters: {'bottleneck_dim': 19, 'hidden_dim': 59, 'lr': 0.0006339857518174262}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:31,958] Trial 9 finished with value: 0.6267806267806267 and parameters: {'bottleneck_dim': 30, 'hidden_dim': 126, 'lr': 0.00020970885892354816}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:33,125] Trial 10 finished with value: 0.7070707070707071 and parameters: {'bottleneck_dim': 10, 'hidden_dim': 255, 'lr': 0.0024186738900212924}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:33,452] Trial 11 finished with value: 0.6666666666666666 and parameters: {'bottleneck_dim': 10, 'hidden_dim': 255, 'lr': 0.002248161485108912}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:33,792] Trial 12 finished with value: 0.6424242424242425 and parameters: {'bottleneck_dim': 15, 'hidden_dim': 249, 'lr': 0.002460154947398923}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:34,143] Trial 13 finished with value: 0.6424242424242425 and parameters: {'bottleneck_dim': 15, 'hidden_dim': 205, 'lr': 0.006530433879610298}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:34,465] Trial 14 finished with value: 0.670995670995671 and parameters: {'bottleneck_dim': 10, 'hidden_dim': 131, 'lr': 0.0013466277938006552}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:34,830] Trial 15 finished with value: 0.6424242424242425 and parameters: {'bottleneck_dim': 20, 'hidden_dim': 179, 'lr': 0.0051146321774643965}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:35,229] Trial 16 finished with value: 0.6424242424242425 and parameters: {'bottleneck_dim': 24, 'hidden_dim': 228, 'lr': 0.0012179012470036254}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:35,429] Trial 17 finished with value: 0.7070707070707071 and parameters: {'bottleneck_dim': 13, 'hidden_dim': 108, 'lr': 0.003754771738024533}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:35,661] Trial 18 finished with value: 0.6868686868686869 and parameters: {'bottleneck_dim': 16, 'hidden_dim': 194, 'lr': 0.0016393458282828286}. Best is trial 1 with value: 0.7167277167277167.\n",
            "[I 2025-07-03 15:40:35,864] Trial 19 finished with value: 0.6646464646464646 and parameters: {'bottleneck_dim': 17, 'hidden_dim': 103, 'lr': 0.004214551382878425}. Best is trial 1 with value: 0.7167277167277167.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:\n",
            "{'bottleneck_dim': 12, 'hidden_dim': 35, 'lr': 0.003833725566317183}\n",
            "\n",
            "ğŸ“Š Final Test Results:\n",
            "Accuracy: 0.7000\n",
            "F1-score: 0.7273\n",
            "AUC: 0.8000\n",
            "Precision: 0.6667\n",
            "Recall (Sensitivity): 0.8000\n",
            "Specificity: 0.2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrEzoCjzEYsn",
        "outputId": "42720417-8c6e-4a22-86ef-71bace160ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting gymnasium<1.2.0,>=0.29.1 (from stable_baselines3)\n",
            "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.0\n",
            "    Uninstalling gymnasium-1.2.0:\n",
            "      Successfully uninstalled gymnasium-1.2.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gymnasium-1.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ø³Ø§Ø®ØªÚ¯ÛŒ: Û²Û· Ù†Ù…ÙˆÙ†Ù‡ØŒ ÛµÛ°Û° ÙˆÛŒÚ˜Ú¯ÛŒØŒ Û² Ú©Ù„Ø§Ø³\n",
        "X, y = make_classification(n_samples=27, n_features=500, n_classes=2, n_informative=20, random_state=42)\n",
        "\n",
        "# Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Ú†ÙˆÙ† ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ú©Ù… Ù‡Ø³ØªØŒ ÛŒÚ© split Ø³Ø§Ø¯Ù‡ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯ÛŒÙ…\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ÙØ¶Ø§ÛŒ action: Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø² Ø¨ÛŒÙ† [8, 16, 32, 64]\n",
        "layer_sizes = [8, 16, 32, 64, 128, 256, 512]\n",
        "\n",
        "class NASEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(NASEnv, self).__init__()\n",
        "        self.action_space = spaces.Discrete(len(layer_sizes))\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
        "        self.state = np.array([0.0], dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "      super().reset(seed=seed)\n",
        "      self.state = np.random.rand(1).astype(np.float32)  # ØªÙˆÙ„ÛŒØ¯ ÛŒÚ© observation Ø¬Ø¯ÛŒØ¯ Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ shape=(1,)\n",
        "      return self.state, {}\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "      hidden_dim = layer_sizes[action]\n",
        "      acc = self._train_and_eval(hidden_dim)\n",
        "      reward = acc\n",
        "      terminated = True   # Ø§Ù¾ÛŒØ²ÙˆØ¯ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø¹Ø¯ Ø§Ø² ÛŒÚ© action ØªÙ…Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "      truncated = False   # Ø§ÛŒÙ†Ø¬Ø§ Ù†ÛŒØ§Ø² Ù†Ø¯Ø§Ø±ÛŒÙ…\n",
        "      info = {\"accuracy\": acc}\n",
        "      self.state = np.array([acc], dtype=np.float32)  # Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„ØŒ Ø¯Ù‚Øª Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† state Ø¨Ø±ÙˆØ² Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "      return self.state, reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "    def _train_and_eval(self, hidden_dim):\n",
        "        model = nn.Sequential(\n",
        "            nn.Linear(X_train.shape[1], hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        X_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "        y_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "        model.train()\n",
        "        for _ in range(10):  # Ú†ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ú©Ù… Ù‡Ø³ØªØŒ Ú†Ù†Ø¯ epoch Ú©ÙˆØªØ§Ù‡\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(X_tensor)\n",
        "            loss = criterion(preds, y_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "            preds = model(X_val_tensor).cpu().numpy().flatten()\n",
        "            preds = (preds >= 0.5).astype(int)\n",
        "            acc = (preds == y_val).mean()\n",
        "        return acc\n",
        "\n",
        "# Ù…Ø­ÛŒØ·\n",
        "env = NASEnv()\n",
        "\n",
        "# Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… PPO\n",
        "model = PPO('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Ø¢Ù…ÙˆØ²Ø´\n",
        "model.learn(total_timesteps=1000)\n",
        "\n",
        "# ØªØ³Øª\n",
        "obs, _ = env.reset()\n",
        "action, _ = model.predict(obs)\n",
        "print(f\"\\nâœ… Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ØªØ±Ù„Ø± (action): {action} â†’ hidden_dim={layer_sizes[action]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95dmlOmt75qw",
        "outputId": "4b2e445f-9c60-4296-f49e-e3a0a00fdf18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1        |\n",
            "|    ep_rew_mean     | 0.497    |\n",
            "| time/              |          |\n",
            "|    fps             | 51       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "\n",
            "âœ… Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ØªØ±Ù„Ø± (action): 2 â†’ hidden_dim=32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs, _ = env.reset()\n",
        "action, _ = model.predict(obs)\n",
        "next_state, reward, terminated, truncated, info = env.step(action)\n",
        "print(f\"Ø±ÛŒÙˆØ§Ø±Ø¯ (Ø¯Ù‚Øª Ù…Ø¯Ù„) Ø¨Ø±Ø§ÛŒ action={action} ({layer_sizes[action]}): {reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNV_3jn0EPlY",
        "outputId": "c0a22747-cbc0-4d34-a97b-24bf36357fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ø±ÛŒÙˆØ§Ø±Ø¯ (Ø¯Ù‚Øª Ù…Ø¯Ù„) Ø¨Ø±Ø§ÛŒ action=2 (32): 0.4444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aP8NY0hOIFGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}